{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Leader Analysis (PTP Obligation Bid Offers/Awards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import calendar\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import os\n",
    "import urllib.request\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "# Handle date time conversions between pandas and matplotlib\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Logistic Regression & LDA\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "#see all columns/rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean Data\n",
    "###  strip/clean column headers, datetime conversion on:\n",
    "\n",
    "##### Environmental: Market Data, Locational Marginal Pricing\n",
    "*Third Party Environmental: NOAA Hourly Weather Data*\n",
    "##### Transactional: Energy Only Offers/Awards\n",
    "*Third Party Transactional: Daily NASDAQ, DOWJONES, ETF prices*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,5,7,8,11,14,19,25,26,27,28,29,30,31,32,33,34,35,36,41,42,43,44,49,51,52,55,56,58,69,71,72,73,75,76,88,89,95,96,97,98,99,100,101,102,103,104,105,106,107,119,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,5,7,8,11,14,19,25,26,27,28,29,30,31,34,35,36,51,55,69,71,75,76,88,89,95,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,19,25,26,27,28,29,30,31,32,34,35,36,42,44,49,55,56,69,71,72,75,76,88,89,95,96,97,98,99,100,101,102,103,104,105,106,107,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#ERCOT\n",
    "market_df = pd.read_excel('OneDrive_1_10-22-2019/ercot_market_data.xlsx', sheet_name = 'ercot_market_data')\n",
    "lmp_df = pd.read_csv('OneDrive_1_10-22-2019/ercotlmp.csv')\n",
    "nodes_df = pd.read_excel('OneDrive_1_10-22-2019/ercot_nodes.xlsx')\n",
    "#PTP Obligation Bids\n",
    "ptp_bids_df = pd.concat([pd.read_csv(f) for f in glob.glob('OneDrive_1_10-22-2019/PTPObligationBids/*.csv')], ignore_index = True)\n",
    "#Awarded PTP OBligation Bids \n",
    "ptp_awards_df = pd.concat([pd.read_csv(f) for f in glob.glob('OneDrive_1_10-22-2019/PTPObligationBidAwards/*.csv')], ignore_index = True)\n",
    "\n",
    "ptp_awards_df.columns = ptp_awards_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace(' - ',' ')\n",
    "ptp_bids_df.columns = ptp_bids_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace(' - ',' ')\n",
    "market_df.columns = market_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "lmp_df.columns = lmp_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "nodes_df.columns = nodes_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "#Convert marketday feature from datetime type to string type\n",
    "market_df['marketday'] = market_df['marketday'].dt.strftime('%m/%d/%Y')\n",
    "ptp_awards_df = ptp_awards_df.rename(columns={'ptp_bid_award_-_mw':'ptp_bid_award_mv', \n",
    "                                                        'ptp_bid_-_price':'ptp_bid_price'})\n",
    "\n",
    "#3rd party data\n",
    "weather_df_1 = pd.read_csv('additional_data/weather_data_1.csv')\n",
    "weather_df_2 = pd.read_csv('additional_data/weather_data_2.csv')\n",
    "weather_df_3 = pd.read_csv('additional_data/weather_data_3.csv')\n",
    "nasdaq_df = pd.read_csv('additional_data/nasdaq_data.csv')\n",
    "etf_df = pd.read_csv('additional_data/etf_data.csv')\n",
    "dowjones_df = pd.read_csv('additional_data/dow_jones_data.csv')\n",
    "\n",
    "weather_df_1.columns = weather_df_1.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "weather_df_2.columns = weather_df_2.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "weather_df_3.columns = weather_df_3.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "nasdaq_df.columns = nasdaq_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "etf_df.columns = etf_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "dowjones_df.columns = dowjones_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "\n",
    "#trim\n",
    "weather_df_1_trim = weather_df_1[['station','date','hourlydewpointtemperature','hourlydrybulbtemperature',\n",
    "                                'hourlyprecipitation','hourlypressuretendency','hourlyrelativehumidity',\n",
    "                                'hourlystationpressure','hourlywetbulbtemperature','hourlywinddirection',\n",
    "                                'hourlywindgustspeed','hourlywindspeed']]\n",
    "weather_df_2_trim = weather_df_2[['station','date','hourlydewpointtemperature','hourlydrybulbtemperature',\n",
    "                                'hourlyprecipitation','hourlypressuretendency','hourlyrelativehumidity',\n",
    "                                'hourlystationpressure','hourlywetbulbtemperature','hourlywinddirection',\n",
    "                                'hourlywindgustspeed','hourlywindspeed']]\n",
    "weather_df_3_trim = weather_df_3[['station','date','hourlydewpointtemperature','hourlydrybulbtemperature',\n",
    "                                'hourlyprecipitation','hourlypressuretendency','hourlyrelativehumidity',\n",
    "                                'hourlystationpressure','hourlywetbulbtemperature','hourlywinddirection',\n",
    "                                'hourlywindgustspeed','hourlywindspeed']]\n",
    "#rename columns\n",
    "nasdaq_df = nasdaq_df.rename(columns={'date':'nasdaq_date','open':'nasdaq_open','high':'nasdaq_high',\n",
    "                                     'low':'nasdaq_low','close':'nasdaq_close','adj Close':'nasdaq_adj_close',\n",
    "                                     'volume':'nasdaq_volume'})\n",
    "etf_df = etf_df.rename(columns={'date':'etf_date','open':'etf_open','high':'etf_high','low':'etf_low',\n",
    "                                     'close':'etf_close','adj Close':'etf_adj_close','volume':'etf_volume'})\n",
    "dowjones_df = dowjones_df.rename(columns={'date':'dowjones_date','open':'dowjones_open','high':'dowjones_high',\n",
    "                                     'low':'dowjones_low','close':'dowjones_close','adj close':'dowjones_adj_close',\n",
    "                                     'volume':'dowjones_volume'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Top 10 Leader Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "lead_ptp_bids = ptp_bids_df.loc[ptp_bids_df['qse_name'].isin(['QLUMN','QNRGTX','QDCENG','QREUEL','QSHELL',\n",
    "                                                              'QDIRE','QPREC','QMONT','QWOLFP','QTIOS'])]\n",
    "lead_ptp_awards = ptp_awards_df.loc[ptp_awards_df['qse_name'].isin(['QLUMN','QNRGTX','QDCENG','QREUEL','QSHELL',\n",
    "                                                                    'QDIRE','QPREC','QMONT','QWOLFP','QTIOS'])]\n",
    "\n",
    "#Select Data within timeline presented in Jeff's Power BI Dashboard (Jan 3, 2019 - July 12, 2019)\n",
    "lead_ptp_awards['date'] = pd.to_datetime(lead_ptp_awards['delivery_date'])\n",
    "mask = (lead_ptp_awards['date'] >= '2019-01-02') & (lead_ptp_awards['date'] < '2019-07-13')\n",
    "lead_ptp_awards = lead_ptp_awards.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Market Data, LMP, & Leader Energy Award Tables = join_energy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join Market Condition & Location Pricing Data\n",
    "market_lmp = lmp_df.merge(market_df, how = 'left', on = ['marketday','hourending','peaktype','month','year'])\n",
    "market_lmp = market_lmp.drop(['datetime_y','year'],axis=1)\n",
    "market_lmp = market_lmp.rename(columns={'datetime_x':'datetime'})\n",
    "market_lmp_nodes = market_lmp.merge(nodes_df, how='left', left_on='settlementpoint', right_on='nodename')\n",
    "lead_ptp_awards = lead_ptp_awards.rename(columns={'delivery_date':'marketday',\n",
    "                                                        'hour_ending':'hourending',\n",
    "                                                        'settlement_point_source':'settlementpoint_src',\n",
    "                                                        'settlement_point_sink':'settlementpoint_snk'})\n",
    "\n",
    "#Join PTP Obligation Bid Award df with joined Market/Price df\n",
    "awards_Src = lead_ptp_awards.merge(market_lmp_nodes, how = 'left', \n",
    "                                          left_on = ['marketday','hourending','settlementpoint_src'],\n",
    "                                          right_on = ['marketday','hourending','settlementpoint'])\n",
    "awards_Snk = lead_ptp_awards.merge(market_lmp_nodes, how = 'left', \n",
    "                                          left_on = ['marketday','hourending','settlementpoint_snk'],\n",
    "                                          right_on = ['marketday','hourending','settlementpoint'])\n",
    "model_dta = pd.concat([awards_Src, awards_Snk])\n",
    "model_dta = model_dta.drop(columns=['iso','weatherstationid','first_dart_date','last_dart_date','equipment','voltage',\n",
    "                                    'substation','nodetype','zoneid','nodename','objectid','date','datetime'])\n",
    "model_dta.loc[(model_dta.nearest_weatherstation == 'TM - Nuevo Laredo/Intl'),'nearest_weatherstation']='TX - Laredo/Intl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = nasdaq_df.merge(etf_df, how='left',left_on='nasdaq_date',right_on='etf_date')\n",
    "stocks_df = stocks_df.merge(dowjones_df, how='left',left_on='nasdaq_date',right_on='dowjones_date')\n",
    "stocks_df = stocks_df.drop(columns=['dowjones_date','etf_date'])\n",
    "stocks_df = stocks_df.rename(columns={'nasdaq_date':'date'})\n",
    "stocks_df['date'] = pd.to_datetime(stocks_df['date'],infer_datetime_format=True)\n",
    "stocks_df['date'] = stocks_df['date'].dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat([weather_df_1_trim, weather_df_2_trim,weather_df_3_trim])\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'],infer_datetime_format=True)\n",
    "weather_df['hourending'] = [d.time() for d in weather_df['date']]\n",
    "mask = (weather_df['date'] >= '2019-01-02') & (weather_df['date'] < '2019-07-13')\n",
    "weather_df = weather_df.loc[mask]\n",
    "hours = [math.ceil((t.hour * 60 + t.minute) / 60) for t in weather_df['hourending']]\n",
    "weather_df['hour'] = hours\n",
    "weather_df['hour']= weather_df['hour'].apply(str).apply(int)\n",
    "weather_df = weather_df.loc[(weather_df['hour'] > 0)]\n",
    "weather_df['date'] = weather_df['date'].dt.strftime('%m/%d/%Y')\n",
    "c_maxes = weather_df.groupby(['station', 'date','hour']).hourending.transform(max)\n",
    "weather_df = weather_df.loc[weather_df.hourending == c_maxes]\n",
    "weather_df['station'] = weather_df['station'].map({72267023042: 'TX - Lubbock/Intl',\n",
    "                                                                 72251012924: 'TX - Corpus Christi/Intl',\n",
    "                                                                 72266013962: 'TX - Abilene/Municipal', \n",
    "                                                                 72250012919: 'TX - Brownsville/Intl', \n",
    "                                                                 72351013966: 'TX - Wichita Falls/Sheppard AFB',\n",
    "                                                                 72261022010: 'TX - Del Rio/Intl',\n",
    "                                                                 72265023023: 'TX - Midland-Odessa',\n",
    "                                                                 72253012921: 'TX - San Antonio/Intl',\n",
    "                                                                 72363023047: 'TX - Amarillo/Intl',\n",
    "                                                                 72248013957: 'LA - Shreveport/Regional',\n",
    "                                                                 72263023034: 'TX - San Angelo/Mathis',\n",
    "                                                                 72265623040: 'TX - Wink/Winkler County',\n",
    "                                                                 72258013960: 'TX - Dallas/Love Field',\n",
    "                                                                 72243012960: 'TX - Houston/Intercontinental',\n",
    "                                                                 72261823091: 'TX - Fort Stockton',\n",
    "                                                                 72252012907: 'TX - Laredo/Intl',\n",
    "                                                                 74641013975: 'OK - Gage/Shattuck',\n",
    "                                                                 72259303985: 'TX - Dallas-Fort Worth/Intl'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df.drop(columns='hourending')\n",
    "weather_df=weather_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_weather_df = weather_df.merge(stocks_df, how = 'left', on='date')\n",
    "stocks_weather_df = stocks_weather_df.fillna(0.00)\n",
    "stocks_weather_df=stocks_weather_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124992, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9712380, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_dta.merge(stocks_weather_df.drop_duplicates(['date','hour','station']), \n",
    "                       how = 'left', \n",
    "                       left_on = ['marketday','hourending','nearest_weatherstation'], \n",
    "                       right_on=['date','hour','station'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9712380, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Evaluation Criterion: PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create PnL column for Performance Measurement/Evaluation Criterion\n",
    "join_ptp_df['PnL'] = (join_ptp_df.dalmp-join_ptp_df.rtlmp) * join_ptp_df.ptp_bid_award_mv\n",
    "\n",
    "#Separate Leaders into dataframes for separate modeling\n",
    "leaders_QLUMN = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QLUMN']\n",
    "leaders_QNRGTX = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QNRGTX']\n",
    "leaders_QDCENG = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QDCENG']\n",
    "leaders_QREUEL = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QREUEL']\n",
    "leaders_QSHELL = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QSHELL']\n",
    "leaders_QDIRE = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QDIRE']\n",
    "leaders_QPREC = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QPREC']\n",
    "leaders_QMONT = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QMONT']\n",
    "leaders_QWOLFP = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QWOLFP']\n",
    "leaders_QTIOS = join_ptp_df.loc[join_ptp_df['qse_name'] == 'QTIOS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders_QLUMN['PnL'].sum() #PnL: 4,938,417.14\n",
    "leaders_QNRGTX['PnL'].sum() #2,245,426.25\n",
    "leaders_QDCENG['PnL'].sum() #1,370,061.43\n",
    "leaders_QREUEL['PnL'].sum() #1,344,345.49\n",
    "PnL = leaders_QSHELL['PnL'].sum() #1,322,784.03\n",
    "leaders_QDIRE['PnL'].sum() #1,228,761.44\n",
    "leaders_QPREC['PnL'].sum() #1,024,767.48\n",
    "leaders_QMONT['PnL'].sum() #979,167.64\n",
    "leaders_QWOLFP['PnL'].sum() #958,999.75\n",
    "leaders_QTIOS['PnL'].sum() #790,331.15\n",
    "PnL \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To perform logistic regression we use the glm method (generalized linear model)\n",
    "\n",
    "#If the encoding is not performed, the glm algorithm encodes the first occerance as 1 and all else as 0\n",
    "# Generally it is good to encode it yourself, so that you know what the output means\n",
    "formula = 'PnL ~ ercot_wind_stwpf_orig + ercot_wind_stwpf_orig/ercot_original_load_forecast + ercot_original_load_forecast'\n",
    "fit1 = smf.glm(formula=formula,data = join_energy_df,family=sm.families.Binomial()).fit()\n",
    "print(fit1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_data['cal_q'],fit1.fittedvalues,'o');\n",
    "plt.xlabel('Calendar Quarter');\n",
    "plt.ylabel('Probability of Cross Purchase');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
