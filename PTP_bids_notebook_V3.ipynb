{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Leader Analysis (PTP Obligation Bid Awards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import calendar\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import os\n",
    "import urllib.request\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "# Handle date time conversions between pandas and matplotlib\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Regression & LDA\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "#see all columns/rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean Data\n",
    "###  strip/clean column headers, datetime conversion on:\n",
    "\n",
    "##### Environmental: Market Data, Locational Marginal Pricing\n",
    "*Third Party Environmental: NOAA Hourly Weather Data*\n",
    "##### Transactional: Energy Only Offers/Awards\n",
    "*Third Party Transactional: Daily NASDAQ, DOWJONES, ETF prices*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,5,7,8,11,14,19,25,26,27,28,29,30,31,32,33,34,35,36,41,42,43,44,49,51,52,55,56,58,69,71,72,73,75,76,88,89,95,96,97,98,99,100,101,102,103,104,105,106,107,119,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,5,7,8,11,14,19,25,26,27,28,29,30,31,34,35,36,51,55,69,71,75,76,88,89,95,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,19,25,26,27,28,29,30,31,32,34,35,36,42,44,49,55,56,69,71,72,75,76,88,89,95,96,97,98,99,100,101,102,103,104,105,106,107,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#import ERCOT\n",
    "market_df = pd.read_excel('OneDrive_1_10-22-2019/ercot_market_data.xlsx', sheet_name = 'ercot_market_data')\n",
    "lmp_df = pd.read_csv('OneDrive_1_10-22-2019/ercotlmp.csv')\n",
    "nodes_df = pd.read_excel('OneDrive_1_10-22-2019/ercot_nodes.xlsx')\n",
    "ptp_awards_df = pd.concat([pd.read_csv(f) for f in glob.glob('OneDrive_1_10-22-2019/PTPObligationBidAwards/*.csv')], ignore_index = True)\n",
    "\n",
    "#strip/clean column headers\n",
    "ptp_awards_df.columns = ptp_awards_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace(' - ',' ')\n",
    "ptp_awards_df = ptp_awards_df.rename(columns={'ptp_bid_award_-_mw':'ptp_bid_award_mw', \n",
    "                                                        'ptp_bid_-_price':'ptp_bid_price'})\n",
    "market_df.columns = market_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "lmp_df.columns = lmp_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "nodes_df.columns = nodes_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "\n",
    "#drop unnecessary columns\n",
    "market_df = market_df.drop(columns=['datetime','year'])\n",
    "lmp_df = lmp_df.drop(columns=['datetime','year'])\n",
    "nodes_df = nodes_df.drop(columns=['iso','weatherstationid','first_dart_date','last_dart_date','equipment','voltage',\n",
    "                                    'substation','nodetype','zoneid','objectid'])\n",
    "\n",
    "#convert marketday feature from datetime type to string type for merging\n",
    "market_df['marketday'] = market_df['marketday'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "#import 3rd party data\n",
    "weather_df_1 = pd.read_csv('additional_data/weather_data_1.csv')\n",
    "weather_df_2 = pd.read_csv('additional_data/weather_data_2.csv')\n",
    "weather_df_3 = pd.read_csv('additional_data/weather_data_3.csv')\n",
    "nasdaq_df = pd.read_csv('additional_data/nasdaq_data.csv')\n",
    "etf_df = pd.read_csv('additional_data/etf_data.csv')\n",
    "dowjones_df = pd.read_csv('additional_data/dow_jones_data.csv')\n",
    "\n",
    "#strip/clean column headers\n",
    "weather_df_1.columns = weather_df_1.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "weather_df_2.columns = weather_df_2.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "weather_df_3.columns = weather_df_3.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "nasdaq_df.columns = nasdaq_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "etf_df.columns = etf_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "dowjones_df.columns = dowjones_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('-','')\n",
    "\n",
    "#Select hourly weather data \n",
    "weather_df_1_trim = weather_df_1[['station','date','hourlydrybulbtemperature','hourlyrelativehumidity',\n",
    "                                'hourlystationpressure','hourlywinddirection','hourlywindspeed']]\n",
    "weather_df_2_trim = weather_df_2[['station','date','hourlydrybulbtemperature','hourlyrelativehumidity',\n",
    "                                'hourlystationpressure','hourlywinddirection','hourlywindspeed']]\n",
    "weather_df_3_trim = weather_df_3[['station','date','hourlydrybulbtemperature','hourlyrelativehumidity',\n",
    "                                'hourlystationpressure','hourlywinddirection','hourlywindspeed']]\n",
    "\n",
    "\n",
    "#rename columns, drop 'close' column and use adjusted close column 'adj_close'\n",
    "nasdaq_df = nasdaq_df.rename(columns={'date':'nasdaq_date','open':'nasdaq_open','high':'nasdaq_high',\n",
    "                                     'low':'nasdaq_low','close':'nasdaq_close','adj_close':'nasdaq_adj_close','volume':'nasdaq_volume'})\n",
    "nasdaq_df = nasdaq_df.drop(columns='nasdaq_close')\n",
    "etf_df = etf_df.rename(columns={'date':'etf_date','open':'etf_open','high':'etf_high','low':'etf_low',\n",
    "                                     'close':'etf_close','adj_close':'etf_adj_close','volume':'etf_volume'})\n",
    "etf_df = etf_df.drop(columns='etf_close')\n",
    "dowjones_df = dowjones_df.rename(columns={'date':'dowjones_date','open':'dowjones_open','high':'dowjones_high',\n",
    "                                     'low':'dowjones_low','close':'dowjones_close','adj_close':'dowjones_adj_close','volume':'dowjones_volume'})\n",
    "dowjones_df = dowjones_df.drop(columns='dowjones_close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Content of ERCOT/ 3rd Party datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### market_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_panhandle_wind_stwpf</th>\n",
       "      <th>panhandle_ercot_rt_generic_constraints</th>\n",
       "      <th>ercot_total_resource_cap_out</th>\n",
       "      <th>ercot_gen_resource</th>\n",
       "      <th>ercot_rtload</th>\n",
       "      <th>ercot_original_load_forecast</th>\n",
       "      <th>ercot_wind_rti</th>\n",
       "      <th>ercot_wind_stwpf_orig</th>\n",
       "      <th>ercot_total_resource_cap_out.1</th>\n",
       "      <th>ercot_renew_resource_cap_out</th>\n",
       "      <th>hourending</th>\n",
       "      <th>marketday</th>\n",
       "      <th>peaktype</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3713.4</td>\n",
       "      <td>3836</td>\n",
       "      <td>8525</td>\n",
       "      <td>50955.2</td>\n",
       "      <td>37081.44343</td>\n",
       "      <td>37031.792114</td>\n",
       "      <td>14317.82</td>\n",
       "      <td>13102.1</td>\n",
       "      <td>8525</td>\n",
       "      <td>1545</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3692.8</td>\n",
       "      <td>3836</td>\n",
       "      <td>8533</td>\n",
       "      <td>51139.2</td>\n",
       "      <td>37258.98993</td>\n",
       "      <td>37486.635803</td>\n",
       "      <td>14126.46</td>\n",
       "      <td>12025.1</td>\n",
       "      <td>8533</td>\n",
       "      <td>1588</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3587.2</td>\n",
       "      <td>3829</td>\n",
       "      <td>8533</td>\n",
       "      <td>51649.4</td>\n",
       "      <td>37300.18780</td>\n",
       "      <td>37394.205750</td>\n",
       "      <td>13686.93</td>\n",
       "      <td>11819.6</td>\n",
       "      <td>8533</td>\n",
       "      <td>1588</td>\n",
       "      <td>3</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3494.1</td>\n",
       "      <td>3826</td>\n",
       "      <td>8533</td>\n",
       "      <td>51116.7</td>\n",
       "      <td>37423.54347</td>\n",
       "      <td>37487.759094</td>\n",
       "      <td>13345.24</td>\n",
       "      <td>11499.3</td>\n",
       "      <td>8533</td>\n",
       "      <td>1569</td>\n",
       "      <td>4</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3426.3</td>\n",
       "      <td>3831</td>\n",
       "      <td>8533</td>\n",
       "      <td>50534.0</td>\n",
       "      <td>37895.21228</td>\n",
       "      <td>38759.001221</td>\n",
       "      <td>13238.17</td>\n",
       "      <td>11146.3</td>\n",
       "      <td>8533</td>\n",
       "      <td>1569</td>\n",
       "      <td>5</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gr_panhandle_wind_stwpf  panhandle_ercot_rt_generic_constraints  \\\n",
       "0                   3713.4                                    3836   \n",
       "1                   3692.8                                    3836   \n",
       "2                   3587.2                                    3829   \n",
       "3                   3494.1                                    3826   \n",
       "4                   3426.3                                    3831   \n",
       "\n",
       "   ercot_total_resource_cap_out  ercot_gen_resource  ercot_rtload  \\\n",
       "0                          8525             50955.2   37081.44343   \n",
       "1                          8533             51139.2   37258.98993   \n",
       "2                          8533             51649.4   37300.18780   \n",
       "3                          8533             51116.7   37423.54347   \n",
       "4                          8533             50534.0   37895.21228   \n",
       "\n",
       "   ercot_original_load_forecast  ercot_wind_rti  ercot_wind_stwpf_orig  \\\n",
       "0                  37031.792114        14317.82                13102.1   \n",
       "1                  37486.635803        14126.46                12025.1   \n",
       "2                  37394.205750        13686.93                11819.6   \n",
       "3                  37487.759094        13345.24                11499.3   \n",
       "4                  38759.001221        13238.17                11146.3   \n",
       "\n",
       "   ercot_total_resource_cap_out.1  ercot_renew_resource_cap_out  hourending  \\\n",
       "0                            8525                          1545           1   \n",
       "1                            8533                          1588           2   \n",
       "2                            8533                          1588           3   \n",
       "3                            8533                          1569           4   \n",
       "4                            8533                          1569           5   \n",
       "\n",
       "    marketday peaktype    month  \n",
       "0  01/01/2019  OFFPEAK  JANUARY  \n",
       "1  01/01/2019  OFFPEAK  JANUARY  \n",
       "2  01/01/2019  OFFPEAK  JANUARY  \n",
       "3  01/01/2019  OFFPEAK  JANUARY  \n",
       "4  01/01/2019  OFFPEAK  JANUARY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodename</th>\n",
       "      <th>zone</th>\n",
       "      <th>nearest_weatherstation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACACIA_UNIT1</td>\n",
       "      <td>WEST</td>\n",
       "      <td>TX - Marfa/Municipal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEEC</td>\n",
       "      <td>WEST</td>\n",
       "      <td>TX - Lubbock/Intl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMISTAD_ALL</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>TX - San Angelo/Mathis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMOCOOIL_CC1</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TX - Houston/Intercontinental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMOCOOIL_CC2</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TX - Houston/Intercontinental</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nodename     zone         nearest_weatherstation\n",
       "0  ACACIA_UNIT1     WEST           TX - Marfa/Municipal\n",
       "1          AEEC     WEST              TX - Lubbock/Intl\n",
       "2   AMISTAD_ALL    SOUTH         TX - San Angelo/Mathis\n",
       "3  AMOCOOIL_CC1  HOUSTON  TX - Houston/Intercontinental\n",
       "4  AMOCOOIL_CC2  HOUSTON  TX - Houston/Intercontinental"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rtlmp</th>\n",
       "      <th>dalmp</th>\n",
       "      <th>hourending</th>\n",
       "      <th>marketday</th>\n",
       "      <th>peaktype</th>\n",
       "      <th>month</th>\n",
       "      <th>settlementpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0175</td>\n",
       "      <td>20.58</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>AEEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.4000</td>\n",
       "      <td>14.48</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>AMISTAD_ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.2350</td>\n",
       "      <td>20.07</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>AMOCOOIL_CC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.2350</td>\n",
       "      <td>20.07</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>AMOCOOIL_CC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.2350</td>\n",
       "      <td>20.07</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>OFFPEAK</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>AMOCO_PUN1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rtlmp  dalmp  hourending   marketday peaktype    month settlementpoint\n",
       "0  13.0175  20.58           1  01/01/2019  OFFPEAK  JANUARY            AEEC\n",
       "1  13.4000  14.48           1  01/01/2019  OFFPEAK  JANUARY     AMISTAD_ALL\n",
       "2  14.2350  20.07           1  01/01/2019  OFFPEAK  JANUARY    AMOCOOIL_CC1\n",
       "3  14.2350  20.07           1  01/01/2019  OFFPEAK  JANUARY    AMOCOOIL_CC2\n",
       "4  14.2350  20.07           1  01/01/2019  OFFPEAK  JANUARY      AMOCO_PUN1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ptp_awards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>hour_ending</th>\n",
       "      <th>qse_name</th>\n",
       "      <th>settlement_point_source</th>\n",
       "      <th>settlement_point_sink</th>\n",
       "      <th>ptp_bid_award_mw</th>\n",
       "      <th>ptp_bid_price</th>\n",
       "      <th>bid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/02/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>QALTU2</td>\n",
       "      <td>FERMI_ALL</td>\n",
       "      <td>AMISTAD_ALL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>47079354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/02/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>QALTU2</td>\n",
       "      <td>FERMI_ALL</td>\n",
       "      <td>AMISTAD_ALL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>47079355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/02/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>QALTU2</td>\n",
       "      <td>FERMI_ALL</td>\n",
       "      <td>AMISTAD_ALL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>47079356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/02/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>QALTU2</td>\n",
       "      <td>FERMI_ALL</td>\n",
       "      <td>AMISTAD_ALL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>47079357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/02/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>QALTU2</td>\n",
       "      <td>FERMI_ALL</td>\n",
       "      <td>AMISTAD_ALL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>47079358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  delivery_date  hour_ending qse_name settlement_point_source  \\\n",
       "0    08/02/2019            1   QALTU2               FERMI_ALL   \n",
       "1    08/02/2019            1   QALTU2               FERMI_ALL   \n",
       "2    08/02/2019            1   QALTU2               FERMI_ALL   \n",
       "3    08/02/2019            1   QALTU2               FERMI_ALL   \n",
       "4    08/02/2019            1   QALTU2               FERMI_ALL   \n",
       "\n",
       "  settlement_point_sink  ptp_bid_award_mw  ptp_bid_price    bid_id  \n",
       "0           AMISTAD_ALL               0.0           16.3  47079354  \n",
       "1           AMISTAD_ALL               0.0           16.3  47079355  \n",
       "2           AMISTAD_ALL               0.0           16.3  47079356  \n",
       "3           AMISTAD_ALL               0.0           16.3  47079357  \n",
       "4           AMISTAD_ALL               0.0           16.3  47079358  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptp_awards_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Weather: weather_df_1_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>hourlydrybulbtemperature</th>\n",
       "      <th>hourlyrelativehumidity</th>\n",
       "      <th>hourlystationpressure</th>\n",
       "      <th>hourlywinddirection</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72267023042</td>\n",
       "      <td>2019-01-01T00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>81.0</td>\n",
       "      <td>26.69</td>\n",
       "      <td>030</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72267023042</td>\n",
       "      <td>2019-01-01T00:53:00</td>\n",
       "      <td>24</td>\n",
       "      <td>84.0</td>\n",
       "      <td>26.74</td>\n",
       "      <td>040</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72267023042</td>\n",
       "      <td>2019-01-01T01:53:00</td>\n",
       "      <td>23</td>\n",
       "      <td>81.0</td>\n",
       "      <td>26.77</td>\n",
       "      <td>020</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72267023042</td>\n",
       "      <td>2019-01-01T02:53:00</td>\n",
       "      <td>22</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.77</td>\n",
       "      <td>040</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72267023042</td>\n",
       "      <td>2019-01-01T03:53:00</td>\n",
       "      <td>22</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.78</td>\n",
       "      <td>050</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station                 date hourlydrybulbtemperature  \\\n",
       "0  72267023042  2019-01-01T00:00:00                       25   \n",
       "1  72267023042  2019-01-01T00:53:00                       24   \n",
       "2  72267023042  2019-01-01T01:53:00                       23   \n",
       "3  72267023042  2019-01-01T02:53:00                       22   \n",
       "4  72267023042  2019-01-01T03:53:00                       22   \n",
       "\n",
       "   hourlyrelativehumidity hourlystationpressure hourlywinddirection  \\\n",
       "0                    81.0                 26.69                 030   \n",
       "1                    84.0                 26.74                 040   \n",
       "2                    81.0                 26.77                 020   \n",
       "3                    82.0                 26.77                 040   \n",
       "4                    82.0                 26.78                 050   \n",
       "\n",
       "  hourlywindspeed  \n",
       "0              22  \n",
       "1              21  \n",
       "2              16  \n",
       "3              21  \n",
       "4              21  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df_1_trim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Stock: nasdaq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nasdaq_date</th>\n",
       "      <th>nasdaq_open</th>\n",
       "      <th>nasdaq_high</th>\n",
       "      <th>nasdaq_low</th>\n",
       "      <th>nasdaq_adj_close</th>\n",
       "      <th>nasdaq_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>6506.910156</td>\n",
       "      <td>6693.709961</td>\n",
       "      <td>6506.879883</td>\n",
       "      <td>6665.939941</td>\n",
       "      <td>2261800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>6584.770020</td>\n",
       "      <td>6600.209961</td>\n",
       "      <td>6457.129883</td>\n",
       "      <td>6463.500000</td>\n",
       "      <td>2607290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>6567.140137</td>\n",
       "      <td>6760.689941</td>\n",
       "      <td>6554.240234</td>\n",
       "      <td>6738.859863</td>\n",
       "      <td>2579550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>6757.529785</td>\n",
       "      <td>6855.600098</td>\n",
       "      <td>6741.399902</td>\n",
       "      <td>6823.470215</td>\n",
       "      <td>2507550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>6893.439941</td>\n",
       "      <td>6909.580078</td>\n",
       "      <td>6795.859863</td>\n",
       "      <td>6897.000000</td>\n",
       "      <td>2380290000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nasdaq_date  nasdaq_open  nasdaq_high   nasdaq_low  nasdaq_adj_close  \\\n",
       "0  2019-01-02  6506.910156  6693.709961  6506.879883       6665.939941   \n",
       "1  2019-01-03  6584.770020  6600.209961  6457.129883       6463.500000   \n",
       "2  2019-01-04  6567.140137  6760.689941  6554.240234       6738.859863   \n",
       "3  2019-01-07  6757.529785  6855.600098  6741.399902       6823.470215   \n",
       "4  2019-01-08  6893.439941  6909.580078  6795.859863       6897.000000   \n",
       "\n",
       "   nasdaq_volume  \n",
       "0     2261800000  \n",
       "1     2607290000  \n",
       "2     2579550000  \n",
       "3     2507550000  \n",
       "4     2380290000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Award Data for Top 10 Leaders in Timeframe 1.3.19 - 7.12.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Top 10 leaders\n",
    "lead_ptp_awards = ptp_awards_df.loc[ptp_awards_df['qse_name'].isin(['QLUMN','QNRGTX','QDCENG','QREUEL','QSHELL',\n",
    "                                                                    'QDIRE','QPREC','QMONT','QWOLFP','QTIOS'])]\n",
    "#Select Data within timeline presented in Jeff's Power BI Dashboard (Jan 2, 2019 - July 12, 2019)\n",
    "lead_ptp_awards['date'] = pd.to_datetime(lead_ptp_awards['delivery_date'])\n",
    "mask = (lead_ptp_awards['date'] >= '2019-01-02') & (lead_ptp_awards['date'] < '2019-07-13')\n",
    "lead_ptp_awards = lead_ptp_awards.loc[mask]\n",
    "\n",
    "#lead_ptp_awards is the base of the merging section to create a model-ready dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Market Data, LMP, & Leader Energy Award Tables = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join Market & Location Pricing & Nodes Data\n",
    "market_lmp = lmp_df.merge(market_df, how = 'left', on = ['marketday','hourending','peaktype','month'])\n",
    "market_lmp_nodes = market_lmp.merge(nodes_df, how='left', left_on='settlementpoint', right_on='nodename') #merge with nodes\n",
    "market_lmp_nodes = market_lmp_nodes.drop(columns='nodename') #drop unnecessary columns\n",
    "#Join PTP Awards with joined Market/Price df\n",
    "lead_ptp_awards = lead_ptp_awards.rename(columns={'delivery_date':'marketday','hour_ending':'hourending',\n",
    "                                                  'settlement_point_source':'settlementpoint_src','settlement_point_sink':'settlementpoint_snk'})\n",
    "awards_Src = lead_ptp_awards.merge(market_lmp_nodes.add_prefix('src_'), how = 'left', \n",
    "                                          left_on = ['marketday','hourending','settlementpoint_src'],\n",
    "                                          right_on = ['src_marketday','src_hourending','src_settlementpoint'])\n",
    "data_ercot = awards_Src.merge(market_lmp_nodes.add_prefix('snk_'), how = 'left', \n",
    "                                          left_on = ['marketday','hourending','settlementpoint_snk'],\n",
    "                                          right_on = ['snk_marketday','snk_hourending','snk_settlementpoint'])\n",
    "data_ercot.loc[(data_ercot.snk_nearest_weatherstation == 'TM - Nuevo Laredo/Intl'),'snk_nearest_weatherstation']='TX - Laredo/Intl'\n",
    "data_ercot.loc[(data_ercot.src_nearest_weatherstation == 'TM - Nuevo Laredo/Intl'),'src_nearest_weatherstation']='TX - Laredo/Intl'\n",
    "data_ercot = data_ercot.fillna(0.0)\n",
    "data_ercot.loc[(data_ercot.snk_zone == 0.0),'snk_zone']='Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4856190, 9)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_ptp_awards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4856190, 47)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ercot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = nasdaq_df.merge(etf_df, how='left',left_on='nasdaq_date',right_on='etf_date')\n",
    "stocks_df = stocks_df.merge(dowjones_df, how='left',left_on='nasdaq_date',right_on='dowjones_date')\n",
    "stocks_df = stocks_df.drop(columns=['dowjones_date','etf_date'])\n",
    "stocks_df = stocks_df.rename(columns={'nasdaq_date':'date'})\n",
    "stocks_df['date'] = pd.to_datetime(stocks_df['date'],infer_datetime_format=True)\n",
    "stocks_df['date'] = stocks_df['date'].dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat([weather_df_1_trim, weather_df_2_trim,weather_df_3_trim])\n",
    "weather_df['hourlydrybulbtemperature'] = pd.to_numeric(weather_df['hourlydrybulbtemperature'], errors='coerce', downcast=None)\n",
    "weather_df['hourlystationpressure'] = pd.to_numeric(weather_df['hourlystationpressure'], errors='coerce', downcast=None)\n",
    "weather_df['hourlywinddirection'] = pd.to_numeric(weather_df['hourlywinddirection'], errors='coerce', downcast=None)\n",
    "weather_df['hourlywindspeed'] = pd.to_numeric(weather_df['hourlywindspeed'], errors='coerce', downcast=None)\n",
    "\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'],infer_datetime_format=True)\n",
    "weather_df['hourending'] = [d.time() for d in weather_df['date']]\n",
    "mask = (weather_df['date'] >= '2019-01-02') & (weather_df['date'] < '2019-07-13')\n",
    "weather_df = weather_df.loc[mask]\n",
    "hours = [math.ceil((t.hour * 60 + t.minute) / 60) for t in weather_df['hourending']]\n",
    "weather_df['hour'] = hours\n",
    "weather_df['hour']= weather_df['hour'].apply(str).apply(int)\n",
    "weather_df = weather_df.loc[(weather_df['hour'] > 0)]\n",
    "weather_df['date'] = weather_df['date'].dt.strftime('%m/%d/%Y')\n",
    "c_maxes = weather_df.groupby(['station', 'date','hour']).hourending.transform(max)\n",
    "weather_df = weather_df.loc[weather_df.hourending == c_maxes]\n",
    "weather_df['station'] = weather_df['station'].map({72267023042: 'TX - Lubbock/Intl',\n",
    "                                                                 72251012924: 'TX - Corpus Christi/Intl',\n",
    "                                                                 72266013962: 'TX - Abilene/Municipal', \n",
    "                                                                 72250012919: 'TX - Brownsville/Intl', \n",
    "                                                                 72351013966: 'TX - Wichita Falls/Sheppard AFB',\n",
    "                                                                 72261022010: 'TX - Del Rio/Intl',\n",
    "                                                                 72265023023: 'TX - Midland-Odessa',\n",
    "                                                                 72253012921: 'TX - San Antonio/Intl',\n",
    "                                                                 72363023047: 'TX - Amarillo/Intl',\n",
    "                                                                 72248013957: 'LA - Shreveport/Regional',\n",
    "                                                                 72263023034: 'TX - San Angelo/Mathis',\n",
    "                                                                 72265623040: 'TX - Wink/Winkler County',\n",
    "                                                                 72258013960: 'TX - Dallas/Love Field',\n",
    "                                                                 72243012960: 'TX - Houston/Intercontinental',\n",
    "                                                                 72261823091: 'TX - Fort Stockton',\n",
    "                                                                 72252012907: 'TX - Laredo/Intl',\n",
    "                                                                 74641013975: 'OK - Gage/Shattuck',\n",
    "                                                                 72259303985: 'TX - Dallas-Fort Worth/Intl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df=weather_df.drop_duplicates(keep='first')\n",
    "data = data_ercot.merge(weather_df.drop_duplicates(['date','hour','station']).add_prefix('src_'), \n",
    "                       how = 'left', \n",
    "                       left_on = ['marketday','hourending','src_nearest_weatherstation'], \n",
    "                       right_on=['src_date','src_hour','src_station'])\n",
    "data = data.merge(weather_df.drop_duplicates(['date','hour','station']).add_prefix('snk_'), \n",
    "                       how = 'left', \n",
    "                       left_on = ['marketday','hourending','snk_nearest_weatherstation'], \n",
    "                       right_on=['snk_date','snk_hour','snk_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(stocks_df, how = 'left', left_on='marketday', right_on='date')\n",
    "data = data.fillna(0.00)\n",
    "data.loc[(data.src_zone == 0.0),'src_zone']='Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4856190, 47)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ercot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4856190, 81)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Evaluation Criterion: PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create PnL column for Performance Measurement/Evaluation Criterion\n",
    "data['PnL'] = ((data.src_dalmp - data.snk_dalmp) - (data.src_rtlmp - data.snk_rtlmp)) * data.ptp_bid_award_mw\n",
    "#Separate Leaders into dataframes for separate modeling\n",
    "leaders_QLUMN = data.loc[data['qse_name'] == 'QLUMN']\n",
    "leaders_QNRGTX = data.loc[data['qse_name'] == 'QNRGTX']\n",
    "leaders_QDCENG = data.loc[data['qse_name'] == 'QDCENG']\n",
    "leaders_QREUEL = data.loc[data['qse_name'] == 'QREUEL']\n",
    "leaders_QSHELL = data.loc[data['qse_name'] == 'QSHELL']\n",
    "leaders_QDIRE = data.loc[data['qse_name'] == 'QDIRE']\n",
    "leaders_QPREC = data.loc[data['qse_name'] == 'QPREC']\n",
    "leaders_QMONT = data.loc[data['qse_name'] == 'QMONT']\n",
    "leaders_QWOLFP = data.loc[data['qse_name'] == 'QWOLFP']\n",
    "leaders_QTIOS = data.loc[data['qse_name'] == 'QTIOS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790331.1544999998"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaders_QLUMN['PnL'].sum() #PnL: 4,938,417.14\n",
    "leaders_QNRGTX['PnL'].sum() #2,245,426.25\n",
    "leaders_QDCENG['PnL'].sum() #1,370,061.43\n",
    "leaders_QREUEL['PnL'].sum() #1,344,345.49\n",
    "leaders_QSHELL['PnL'].sum() #1,322,784.03\n",
    "leaders_QDIRE['PnL'].sum() #1,228,761.44\n",
    "leaders_QPREC['PnL'].sum() #1,024,767.48\n",
    "leaders_QMONT['PnL'].sum() #979,167.64\n",
    "leaders_QWOLFP['PnL'].sum() #958,999.75\n",
    "PnL = leaders_QTIOS['PnL'].sum() #790,331.15\n",
    "PnL \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test 1: Linear Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "leader = leaders_QLUMN\n",
    "leader =leader.drop(columns=['marketday','qse_name','ptp_bid_price','bid_id','date_x','src_hourending_x','src_settlementpoint','snk_hourending_x','snk_month','snk_settlementpoint','src_station','src_hourending_y','snk_station','snk_hourending_y','date_y','src_marketday','snk_marketday','src_date','snk_date','src_hour','snk_hour', 'src_nearest_weatherstation','snk_nearest_weatherstation','snk_ercot_total_resource_cap_out.1','snk_rtlmp','src_rtlmp'])\n",
    "leader = leader.fillna(0.00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = leader.iloc[:,:-1].values\n",
    "y =leader.iloc[:,55].values\n",
    "labelencoder_x=LabelEncoder()\n",
    "x[:,1]=labelencoder_x.fit_transform(x[:,1])\n",
    "x[:,2]=labelencoder_x.fit_transform(x[:,2])\n",
    "x[:,5]=labelencoder_x.fit_transform(x[:,5])\n",
    "x[:,6]=labelencoder_x.fit_transform(x[:,6])\n",
    "x[:,17]=labelencoder_x.fit_transform(x[:,17])\n",
    "x[:,19]=labelencoder_x.fit_transform(x[:,19])\n",
    "x[:,29]=labelencoder_x.fit_transform(x[:,29])\n",
    "\n",
    "\n",
    "#onehotencoder=OneHotEncoder(categorical_features =[1])\n",
    "#x =onehotencoder.fit_transform(x).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting training set and testing set\n",
    "xtrain, xtest, ytrain, ytest =train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# Training the Multivariate Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(xtrain, ytrain)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_prediction= regressor.predict(xtest)\n",
    "\n",
    "# Backward Eliminiation\n",
    "\n",
    "# Insert B Intercept\n",
    "X=np.append(arr = np.ones((259246,1)).astype(int), values = x, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.003</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.003</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   41.93</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>2.29e-148</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:03:30</td>     <th>  Log-Likelihood:    </th> <td>-2.3084e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>259246</td>      <th>  AIC:               </th>  <td>4.617e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>259227</td>      <th>  BIC:               </th>  <td>4.617e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -245.7651</td> <td>   83.217</td> <td>   -2.953</td> <td> 0.003</td> <td> -408.867</td> <td>  -82.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.3767</td> <td>    0.631</td> <td>   -0.597</td> <td> 0.551</td> <td>   -1.613</td> <td>    0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -5.2854</td> <td>    0.899</td> <td>   -5.881</td> <td> 0.000</td> <td>   -7.047</td> <td>   -3.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -7.3497</td> <td>    1.598</td> <td>   -4.600</td> <td> 0.000</td> <td>  -10.481</td> <td>   -4.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1402</td> <td>    0.023</td> <td>    6.193</td> <td> 0.000</td> <td>    0.096</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -7.3752</td> <td>    1.421</td> <td>   -5.191</td> <td> 0.000</td> <td>  -10.160</td> <td>   -4.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.5707</td> <td>    2.809</td> <td>    0.203</td> <td> 0.839</td> <td>   -4.934</td> <td>    6.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    2.5496</td> <td>    2.339</td> <td>    1.090</td> <td> 0.276</td> <td>   -2.035</td> <td>    7.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0146</td> <td>    0.002</td> <td>    6.384</td> <td> 0.000</td> <td>    0.010</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0066</td> <td>    0.007</td> <td>   -0.938</td> <td> 0.348</td> <td>   -0.020</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0030</td> <td>    0.000</td> <td>    9.773</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0024</td> <td>    0.001</td> <td>    2.761</td> <td> 0.006</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0024</td> <td>    0.001</td> <td>    2.273</td> <td> 0.023</td> <td>    0.000</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0033</td> <td>    0.001</td> <td>   -2.907</td> <td> 0.004</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0223</td> <td>    0.001</td> <td>  -17.687</td> <td> 0.000</td> <td>   -0.025</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.0217</td> <td>    0.001</td> <td>   18.138</td> <td> 0.000</td> <td>    0.019</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0030</td> <td>    0.000</td> <td>    9.773</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0017</td> <td>    0.004</td> <td>    0.415</td> <td> 0.678</td> <td>   -0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    8.8290</td> <td>    6.409</td> <td>    1.378</td> <td> 0.168</td> <td>   -3.732</td> <td>   21.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    6.9594</td> <td>    1.402</td> <td>    4.963</td> <td> 0.000</td> <td>    4.211</td> <td>    9.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.5707</td> <td>    2.809</td> <td>    0.203</td> <td> 0.839</td> <td>   -4.934</td> <td>    6.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0146</td> <td>    0.002</td> <td>    6.384</td> <td> 0.000</td> <td>    0.010</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0066</td> <td>    0.007</td> <td>   -0.938</td> <td> 0.348</td> <td>   -0.020</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.0030</td> <td>    0.000</td> <td>    9.773</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.0024</td> <td>    0.001</td> <td>    2.761</td> <td> 0.006</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.0024</td> <td>    0.001</td> <td>    2.273</td> <td> 0.023</td> <td>    0.000</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0033</td> <td>    0.001</td> <td>   -2.907</td> <td> 0.004</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.0223</td> <td>    0.001</td> <td>  -17.687</td> <td> 0.000</td> <td>   -0.025</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.0217</td> <td>    0.001</td> <td>   18.138</td> <td> 0.000</td> <td>    0.019</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.0017</td> <td>    0.004</td> <td>    0.415</td> <td> 0.678</td> <td>   -0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>704959.837</td> <th>  Durbin-Watson:     </th>     <td>   1.002</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>120114179255.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>33.100</td>   <th>  Prob(JB):          </th>     <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>3336.966</td>  <th>  Cond. No.          </th>     <td>2.07e+16</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.78e-18. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     41.93\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):          2.29e-148\n",
       "Time:                        17:03:30   Log-Likelihood:            -2.3084e+06\n",
       "No. Observations:              259246   AIC:                         4.617e+06\n",
       "Df Residuals:                  259227   BIC:                         4.617e+06\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -245.7651     83.217     -2.953      0.003    -408.867     -82.663\n",
       "x1            -0.3767      0.631     -0.597      0.551      -1.613       0.860\n",
       "x2            -5.2854      0.899     -5.881      0.000      -7.047      -3.524\n",
       "x3            -7.3497      1.598     -4.600      0.000     -10.481      -4.218\n",
       "x4             0.1402      0.023      6.193      0.000       0.096       0.185\n",
       "x5            -7.3752      1.421     -5.191      0.000     -10.160      -4.591\n",
       "x6             0.5707      2.809      0.203      0.839      -4.934       6.076\n",
       "x7             2.5496      2.339      1.090      0.276      -2.035       7.134\n",
       "x8             0.0146      0.002      6.384      0.000       0.010       0.019\n",
       "x9            -0.0066      0.007     -0.938      0.348      -0.020       0.007\n",
       "x10            0.0030      0.000      9.773      0.000       0.002       0.004\n",
       "x11            0.0024      0.001      2.761      0.006       0.001       0.004\n",
       "x12            0.0024      0.001      2.273      0.023       0.000       0.005\n",
       "x13           -0.0033      0.001     -2.907      0.004      -0.005      -0.001\n",
       "x14           -0.0223      0.001    -17.687      0.000      -0.025      -0.020\n",
       "x15            0.0217      0.001     18.138      0.000       0.019       0.024\n",
       "x16            0.0030      0.000      9.773      0.000       0.002       0.004\n",
       "x17            0.0017      0.004      0.415      0.678      -0.007       0.010\n",
       "x18            8.8290      6.409      1.378      0.168      -3.732      21.390\n",
       "x19            6.9594      1.402      4.963      0.000       4.211       9.708\n",
       "x20            0.5707      2.809      0.203      0.839      -4.934       6.076\n",
       "x21            0.0146      0.002      6.384      0.000       0.010       0.019\n",
       "x22           -0.0066      0.007     -0.938      0.348      -0.020       0.007\n",
       "x23            0.0030      0.000      9.773      0.000       0.002       0.004\n",
       "x24            0.0024      0.001      2.761      0.006       0.001       0.004\n",
       "x25            0.0024      0.001      2.273      0.023       0.000       0.005\n",
       "x26           -0.0033      0.001     -2.907      0.004      -0.005      -0.001\n",
       "x27           -0.0223      0.001    -17.687      0.000      -0.025      -0.020\n",
       "x28            0.0217      0.001     18.138      0.000       0.019       0.024\n",
       "x29            0.0017      0.004      0.415      0.678      -0.007       0.010\n",
       "==============================================================================\n",
       "Omnibus:                   704959.837   Durbin-Watson:                   1.002\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     120114179255.895\n",
       "Skew:                          33.100   Prob(JB):                         0.00\n",
       "Kurtosis:                    3336.966   Cond. No.                     2.07e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.78e-18. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call Ordinary Least Square\n",
    "xelimination = X[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]]\n",
    "xelimination = np.array(xelimination, dtype=float)\n",
    "regressorOLS = smf.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   22.82</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>2.27e-104</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:20:05</td>     <th>  Log-Likelihood:    </th> <td>-2.3085e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>259246</td>      <th>  AIC:               </th>  <td>4.617e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>259220</td>      <th>  BIC:               </th>  <td>4.617e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    25</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  -15.2521</td> <td>   18.595</td> <td>   -0.820</td> <td> 0.412</td> <td>  -51.697</td> <td>   21.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    3.1140</td> <td>    3.005</td> <td>    1.036</td> <td> 0.300</td> <td>   -2.776</td> <td>    9.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.6092</td> <td>    0.720</td> <td>   -0.847</td> <td> 0.397</td> <td>   -2.020</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.7429</td> <td>    0.347</td> <td>    2.138</td> <td> 0.032</td> <td>    0.062</td> <td>    1.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -4.1912</td> <td>    2.426</td> <td>   -1.728</td> <td> 0.084</td> <td>   -8.945</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0169</td> <td>    0.046</td> <td>    0.368</td> <td> 0.713</td> <td>   -0.073</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    5.6891</td> <td>    1.075</td> <td>    5.291</td> <td> 0.000</td> <td>    3.582</td> <td>    7.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0055</td> <td>    0.699</td> <td>   -0.008</td> <td> 0.994</td> <td>   -1.376</td> <td>    1.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    1.5403</td> <td>    0.349</td> <td>    4.410</td> <td> 0.000</td> <td>    0.856</td> <td>    2.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0247</td> <td>    2.318</td> <td>    0.011</td> <td> 0.991</td> <td>   -4.518</td> <td>    4.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0770</td> <td>    0.047</td> <td>   -1.621</td> <td> 0.105</td> <td>   -0.170</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -3.2444</td> <td>    1.082</td> <td>   -2.999</td> <td> 0.003</td> <td>   -5.365</td> <td>   -1.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -2.0042</td> <td>    0.216</td> <td>   -9.271</td> <td> 0.000</td> <td>   -2.428</td> <td>   -1.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    2.3680</td> <td>    0.308</td> <td>    7.700</td> <td> 0.000</td> <td>    1.765</td> <td>    2.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    1.3529</td> <td>    0.298</td> <td>    4.546</td> <td> 0.000</td> <td>    0.770</td> <td>    1.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -1.5759</td> <td>    0.310</td> <td>   -5.091</td> <td> 0.000</td> <td>   -2.183</td> <td>   -0.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 4.296e-08</td> <td> 1.01e-08</td> <td>    4.268</td> <td> 0.000</td> <td> 2.32e-08</td> <td> 6.27e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>  -17.1711</td> <td>   13.229</td> <td>   -1.298</td> <td> 0.194</td> <td>  -43.099</td> <td>    8.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>  -93.3000</td> <td>   17.742</td> <td>   -5.259</td> <td> 0.000</td> <td> -128.074</td> <td>  -58.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>  106.9705</td> <td>   15.654</td> <td>    6.833</td> <td> 0.000</td> <td>   76.288</td> <td>  137.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   18.1035</td> <td>   12.377</td> <td>    1.463</td> <td> 0.144</td> <td>   -6.154</td> <td>   42.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.0002</td> <td> 2.66e-05</td> <td>   -7.689</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.5706</td> <td>    0.080</td> <td>    7.092</td> <td> 0.000</td> <td>    0.413</td> <td>    0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.6726</td> <td>    0.117</td> <td>   -5.730</td> <td> 0.000</td> <td>   -0.903</td> <td>   -0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.2945</td> <td>    0.099</td> <td>   -2.982</td> <td> 0.003</td> <td>   -0.488</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.3124</td> <td>    0.111</td> <td>    2.811</td> <td> 0.005</td> <td>    0.095</td> <td>    0.530</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>706087.187</td> <th>  Durbin-Watson:     </th>     <td>   1.002</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>120723918418.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>33.245</td>   <th>  Prob(JB):          </th>     <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>3345.415</td>  <th>  Cond. No.          </th>     <td>1.14e+10</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.14e+10. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.002\n",
       "Model:                            OLS   Adj. R-squared:                  0.002\n",
       "Method:                 Least Squares   F-statistic:                     22.82\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):          2.27e-104\n",
       "Time:                        17:20:05   Log-Likelihood:            -2.3085e+06\n",
       "No. Observations:              259246   AIC:                         4.617e+06\n",
       "Df Residuals:                  259220   BIC:                         4.617e+06\n",
       "Df Model:                          25                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -15.2521     18.595     -0.820      0.412     -51.697      21.193\n",
       "x1             3.1140      3.005      1.036      0.300      -2.776       9.004\n",
       "x2            -0.6092      0.720     -0.847      0.397      -2.020       0.801\n",
       "x3             0.7429      0.347      2.138      0.032       0.062       1.424\n",
       "x4            -4.1912      2.426     -1.728      0.084      -8.945       0.563\n",
       "x5             0.0169      0.046      0.368      0.713      -0.073       0.107\n",
       "x6             5.6891      1.075      5.291      0.000       3.582       7.796\n",
       "x7            -0.0055      0.699     -0.008      0.994      -1.376       1.365\n",
       "x8             1.5403      0.349      4.410      0.000       0.856       2.225\n",
       "x9             0.0247      2.318      0.011      0.991      -4.518       4.568\n",
       "x10           -0.0770      0.047     -1.621      0.105      -0.170       0.016\n",
       "x11           -3.2444      1.082     -2.999      0.003      -5.365      -1.124\n",
       "x12           -2.0042      0.216     -9.271      0.000      -2.428      -1.581\n",
       "x13            2.3680      0.308      7.700      0.000       1.765       2.971\n",
       "x14            1.3529      0.298      4.546      0.000       0.770       1.936\n",
       "x15           -1.5759      0.310     -5.091      0.000      -2.183      -0.969\n",
       "x16         4.296e-08   1.01e-08      4.268      0.000    2.32e-08    6.27e-08\n",
       "x17          -17.1711     13.229     -1.298      0.194     -43.099       8.757\n",
       "x18          -93.3000     17.742     -5.259      0.000    -128.074     -58.526\n",
       "x19          106.9705     15.654      6.833      0.000      76.288     137.653\n",
       "x20           18.1035     12.377      1.463      0.144      -6.154      42.361\n",
       "x21           -0.0002   2.66e-05     -7.689      0.000      -0.000      -0.000\n",
       "x22            0.5706      0.080      7.092      0.000       0.413       0.728\n",
       "x23           -0.6726      0.117     -5.730      0.000      -0.903      -0.443\n",
       "x24           -0.2945      0.099     -2.982      0.003      -0.488      -0.101\n",
       "x25            0.3124      0.111      2.811      0.005       0.095       0.530\n",
       "==============================================================================\n",
       "Omnibus:                   706087.187   Durbin-Watson:                   1.002\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     120723918418.885\n",
       "Skew:                          33.245   Prob(JB):                         0.00\n",
       "Kurtosis:                    3345.415   Cond. No.                     1.14e+10\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.14e+10. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call Ordinary Least Square\n",
    "xelimination = X[:,[0,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54]]\n",
    "xelimination = np.array(xelimination, dtype=float)\n",
    "regressorOLS = smf.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.003</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.003</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   57.36</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>4.54e-162</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:52:50</td>     <th>  Log-Likelihood:    </th> <td>-2.3084e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>259246</td>      <th>  AIC:               </th>  <td>4.617e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>259231</td>      <th>  BIC:               </th>  <td>4.617e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -395.5687</td> <td>   88.446</td> <td>   -4.472</td> <td> 0.000</td> <td> -568.920</td> <td> -222.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0335</td> <td>    0.005</td> <td>    7.327</td> <td> 0.000</td> <td>    0.025</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0118</td> <td>    0.008</td> <td>   -1.533</td> <td> 0.125</td> <td>   -0.027</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0033</td> <td>    0.000</td> <td>   10.964</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0029</td> <td>    0.001</td> <td>    3.517</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0026</td> <td>    0.001</td> <td>    2.457</td> <td> 0.014</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0029</td> <td>    0.001</td> <td>   -2.629</td> <td> 0.009</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0219</td> <td>    0.001</td> <td>  -17.447</td> <td> 0.000</td> <td>   -0.024</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0211</td> <td>    0.001</td> <td>   17.713</td> <td> 0.000</td> <td>    0.019</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0033</td> <td>    0.000</td> <td>   10.964</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0081</td> <td>    0.004</td> <td>   -1.936</td> <td> 0.053</td> <td>   -0.016</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0118</td> <td>    0.008</td> <td>   -1.533</td> <td> 0.125</td> <td>   -0.027</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0033</td> <td>    0.000</td> <td>   10.964</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0029</td> <td>    0.001</td> <td>    3.517</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0026</td> <td>    0.001</td> <td>    2.457</td> <td> 0.014</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0029</td> <td>    0.001</td> <td>   -2.629</td> <td> 0.009</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0219</td> <td>    0.001</td> <td>  -17.447</td> <td> 0.000</td> <td>   -0.024</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0211</td> <td>    0.001</td> <td>   17.713</td> <td> 0.000</td> <td>    0.019</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0081</td> <td>    0.004</td> <td>   -1.936</td> <td> 0.053</td> <td>   -0.016</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0122</td> <td>    0.034</td> <td>   -0.355</td> <td> 0.723</td> <td>   -0.079</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.8347</td> <td>    0.230</td> <td>   -3.637</td> <td> 0.000</td> <td>   -1.285</td> <td>   -0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    1.6643</td> <td>    0.184</td> <td>    9.056</td> <td> 0.000</td> <td>    1.304</td> <td>    2.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> 3.967e-08</td> <td> 4.56e-09</td> <td>    8.703</td> <td> 0.000</td> <td> 3.07e-08</td> <td> 4.86e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.0002</td> <td> 2.37e-05</td> <td>   -8.902</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>705757.349</td> <th>  Durbin-Watson:     </th>     <td>   1.003</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>120819640312.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>33.201</td>   <th>  Prob(JB):          </th>     <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>3346.742</td>  <th>  Cond. No.          </th>     <td>4.24e+22</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.04e-22. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     57.36\n",
       "Date:                Fri, 08 Nov 2019   Prob (F-statistic):          4.54e-162\n",
       "Time:                        17:52:50   Log-Likelihood:            -2.3084e+06\n",
       "No. Observations:              259246   AIC:                         4.617e+06\n",
       "Df Residuals:                  259231   BIC:                         4.617e+06\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -395.5687     88.446     -4.472      0.000    -568.920    -222.218\n",
       "x1             0.0335      0.005      7.327      0.000       0.025       0.043\n",
       "x2            -0.0118      0.008     -1.533      0.125      -0.027       0.003\n",
       "x3             0.0033      0.000     10.964      0.000       0.003       0.004\n",
       "x4             0.0029      0.001      3.517      0.000       0.001       0.005\n",
       "x5             0.0026      0.001      2.457      0.014       0.001       0.005\n",
       "x6            -0.0029      0.001     -2.629      0.009      -0.005      -0.001\n",
       "x7            -0.0219      0.001    -17.447      0.000      -0.024      -0.019\n",
       "x8             0.0211      0.001     17.713      0.000       0.019       0.023\n",
       "x9             0.0033      0.000     10.964      0.000       0.003       0.004\n",
       "x10           -0.0081      0.004     -1.936      0.053      -0.016       0.000\n",
       "x11           -0.0118      0.008     -1.533      0.125      -0.027       0.003\n",
       "x12            0.0033      0.000     10.964      0.000       0.003       0.004\n",
       "x13            0.0029      0.001      3.517      0.000       0.001       0.005\n",
       "x14            0.0026      0.001      2.457      0.014       0.001       0.005\n",
       "x15           -0.0029      0.001     -2.629      0.009      -0.005      -0.001\n",
       "x16           -0.0219      0.001    -17.447      0.000      -0.024      -0.019\n",
       "x17            0.0211      0.001     17.713      0.000       0.019       0.023\n",
       "x18           -0.0081      0.004     -1.936      0.053      -0.016       0.000\n",
       "x19           -0.0122      0.034     -0.355      0.723      -0.079       0.055\n",
       "x20           -0.8347      0.230     -3.637      0.000      -1.285      -0.385\n",
       "x21            1.6643      0.184      9.056      0.000       1.304       2.024\n",
       "x22         3.967e-08   4.56e-09      8.703      0.000    3.07e-08    4.86e-08\n",
       "x23           -0.0002   2.37e-05     -8.902      0.000      -0.000      -0.000\n",
       "==============================================================================\n",
       "Omnibus:                   705757.349   Durbin-Watson:                   1.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     120819640312.043\n",
       "Skew:                          33.201   Prob(JB):                         0.00\n",
       "Kurtosis:                    3346.742   Cond. No.                     4.24e+22\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.04e-22. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call Ordinary Least Square\n",
    "xelimination = X[:,[0,8,9,10,11,12,13,14,15,16,17,22,23,24,25,26,27,28,29,34,36,37,45,50]]\n",
    "xelimination = np.array(xelimination, dtype=float)\n",
    "regressorOLS = smf.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1}\n",
      "-3125154.613872563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-4,1e-3,1e-2,1,5,10,20]}\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error',cv=20)\n",
    "lasso_regressor.fit(xtrain,ytrain)\n",
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(xtrain,ytrain)\n",
    "train_score=lasso.score(xtrain,ytrain)\n",
    "test_score=lasso.score(xtest,ytest)\n",
    "coeff_used = np.sum(lasso.coef_!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.003958540245053377\n",
      "test score:  0.0036012144927155543\n",
      "number of features used:  52\n"
     ]
    }
   ],
   "source": [
    "print( \"training score:\", train_score )\n",
    "print( \"test score: \", test_score)\n",
    "print (\"number of features used: \", coeff_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score for alpha=0.01: 0.003961652722870412\n",
      "test score for alpha =0.01:  0.0036106960299957525\n",
      "number of features used: for alpha =0.01: 55\n"
     ]
    }
   ],
   "source": [
    "lasso001 = Lasso(alpha=0.01, max_iter=10e2)\n",
    "lasso001.fit(xtrain,ytrain)\n",
    "train_score001=lasso001.score(xtrain,ytrain)\n",
    "test_score001=lasso001.score(xtest,ytest)\n",
    "coeff_used001 = np.sum(lasso001.coef_!=0)\n",
    "print (\"training score for alpha=0.01:\", train_score001 )\n",
    "print (\"test score for alpha =0.01: \", test_score001)\n",
    "print (\"number of features used: for alpha =0.01:\", coeff_used001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinsanders/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score for alpha=0.0001: 0.003961590392129621\n",
      "test score for alpha =0.0001:  0.0036106852912333176\n",
      "number of features used: for alpha =0.0001: 55\n"
     ]
    }
   ],
   "source": [
    "lasso00001 = Lasso(alpha=0.0001, max_iter=10e2)\n",
    "lasso00001.fit(xtrain,ytrain)\n",
    "train_score00001=lasso00001.score(xtrain,ytrain)\n",
    "test_score00001=lasso00001.score(xtest,ytest)\n",
    "coeff_used00001 = np.sum(lasso00001.coef_!=0)\n",
    "print (\"training score for alpha=0.0001:\", train_score00001 )\n",
    "print (\"test score for alpha =0.0001: \", test_score00001)\n",
    "print (\"number of features used: for alpha =0.0001:\", coeff_used00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
